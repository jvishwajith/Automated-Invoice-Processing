{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 12:01:38,155 - INFO - Model loaded successfully on cpu\n",
      "2025-01-19 12:01:38,156 - INFO - Model initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 AWB-No, 1 FOB-Value-in-INR, 1 Goods-Description, 1 Non-GST-Invoice-No, 1 Qty, 1 Total-Value, 1 Unit-Value, 48.0ms\n",
      "Speed: 3.0ms preprocess, 48.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 12:01:38,282 - INFO - Saved Total-Value (conf: 0.96) to d:\\Github_Projects\\VTM_Final_Src_Code_Git_Connected\\inference\\1_jpg\\Total-Value.jpg\n",
      "2025-01-19 12:01:38,284 - INFO - Saved Qty (conf: 0.91) to d:\\Github_Projects\\VTM_Final_Src_Code_Git_Connected\\inference\\1_jpg\\Qty.jpg\n",
      "2025-01-19 12:01:38,286 - INFO - Saved Non-GST-Invoice-No (conf: 0.91) to d:\\Github_Projects\\VTM_Final_Src_Code_Git_Connected\\inference\\1_jpg\\Non-GST-Invoice-No.jpg\n",
      "2025-01-19 12:01:38,288 - INFO - Saved FOB-Value-in-INR (conf: 0.90) to d:\\Github_Projects\\VTM_Final_Src_Code_Git_Connected\\inference\\1_jpg\\FOB-Value-in-INR.jpg\n",
      "2025-01-19 12:01:38,290 - INFO - Saved Unit-Value (conf: 0.90) to d:\\Github_Projects\\VTM_Final_Src_Code_Git_Connected\\inference\\1_jpg\\Unit-Value.jpg\n",
      "2025-01-19 12:01:38,294 - INFO - Saved Goods-Description (conf: 0.82) to d:\\Github_Projects\\VTM_Final_Src_Code_Git_Connected\\inference\\1_jpg\\Goods-Description.jpg\n",
      "2025-01-19 12:01:38,297 - INFO - Saved AWB-No (conf: 0.64) to d:\\Github_Projects\\VTM_Final_Src_Code_Git_Connected\\inference\\1_jpg\\AWB-No.jpg\n",
      "2025-01-19 12:01:38,297 - INFO - Processed 1.jpg: Found 7 fields\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing completed successfully!\n",
      "Cropped fields saved to: d:\\Github_Projects\\VTM_Final_Src_Code_Git_Connected\\inference\\1_jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FieldExtractor:\n",
    "    def __init__(self, model_path, output_dir=None):\n",
    "        # Class names matching your training\n",
    "        self.classes = [\n",
    "            'AWB-No', 'FOB-Value-in-INR', 'Goods-Description', \n",
    "            'Non-GST-Invoice-No', 'Qty', 'Total-Value', 'Unit-Value'\n",
    "        ]\n",
    "        \n",
    "        # Store paths\n",
    "        self.model_path = model_path\n",
    "        # Set output directory to local 'inference' folder if not specified\n",
    "        self.output_base_dir = output_dir if output_dir else os.path.join(os.getcwd(), 'inference')\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(self.output_base_dir, exist_ok=True)\n",
    "        \n",
    "        # Load the model\n",
    "        self.load_model()\n",
    "        \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the YOLOv8 model\"\"\"\n",
    "        try:\n",
    "            self.model = YOLO(self.model_path)\n",
    "            # Move to GPU if available\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            self.model.to(self.device)\n",
    "            logger.info(f\"Model loaded successfully on {self.device}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def process_image(self, image_path, conf_threshold=0.25):\n",
    "        \"\"\"\n",
    "        Process a single image and extract fields\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to the input image\n",
    "            conf_threshold (float): Confidence threshold for detections\n",
    "            \n",
    "        Returns:\n",
    "            str: Path to the output directory containing cropped fields\n",
    "        \"\"\"\n",
    "        try:\n",
    "        \n",
    "            output_dir = os.path.join(\n",
    "                self.output_base_dir,\n",
    "                f\"{Path(image_path).stem}_jpg\"\n",
    "            )\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # Read image\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Could not read image: {image_path}\")\n",
    "            \n",
    "            # Get predictions\n",
    "            results = self.model(image)[0]\n",
    "            \n",
    "            # Process each detection\n",
    "            detections_count = 0\n",
    "            for det in results.boxes.data:\n",
    "                x1, y1, x2, y2, conf, cls = det\n",
    "                \n",
    "                # Skip low confidence detections\n",
    "                if conf < conf_threshold:\n",
    "                    continue\n",
    "                    \n",
    "                # Convert coordinates to integers\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                class_name = self.classes[int(cls)]\n",
    "                \n",
    "                # Crop the field\n",
    "                field_crop = image[y1:y2, x1:x2]\n",
    "                \n",
    "                # Save cropped image\n",
    "                output_path = os.path.join(output_dir, f\"{class_name}.jpg\")\n",
    "                cv2.imwrite(output_path, field_crop)\n",
    "                \n",
    "                detections_count += 1\n",
    "                logger.info(f\"Saved {class_name} (conf: {conf:.2f}) to {output_path}\")\n",
    "            \n",
    "            logger.info(f\"Processed {image_path}: Found {detections_count} fields\")\n",
    "            return output_dir\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing image {image_path}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    # Define paths (modify these according to your setup)\n",
    "    model_path = \"best.pt\"  # Path to your trained model\n",
    "    image_path = \"1.jpg\"  # Path to your test image\n",
    "    \n",
    "    # Initialize the extractor (without specifying output_dir to use local inference folder)\n",
    "    try:\n",
    "        extractor = FieldExtractor(model_path)\n",
    "        logger.info(\"Model initialized successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize model: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Process the image\n",
    "    try:\n",
    "        output_dir = extractor.process_image(image_path)\n",
    "        print(f\"\\nProcessing completed successfully!\")\n",
    "        print(f\"Cropped fields saved to: {output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during processing: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
